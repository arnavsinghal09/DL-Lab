{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycQHsqaH3mLb",
        "outputId": "e8fa8b4e-9521-47fa-a58f-142baa9de056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.64MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.26MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.18MB/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "val_dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(y, num_classes=10):\n",
        "    out = np.zeros((y.shape[0], num_classes))\n",
        "    out[np.arange(y.shape[0]), y] = 1\n",
        "    return out\n",
        "\n",
        "def preprocess(images, labels):\n",
        "    X = images.numpy().reshape(images.shape[0], -1)   # (B,784)\n",
        "    y = one_hot(labels.numpy())\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "OUFROm-m3vFc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x): return np.maximum(0, x)\n",
        "def relu_deriv(x): return (x > 0).astype(float)\n",
        "\n",
        "def sigmoid(x): return 1/(1+np.exp(-x))\n",
        "def sigmoid_deriv(x):\n",
        "    s = sigmoid(x)\n",
        "    return s*(1-s)\n",
        "\n",
        "def tanh(x): return np.tanh(x)\n",
        "def tanh_deriv(x): return 1 - np.tanh(x)**2\n",
        "\n",
        "def softmax(x):\n",
        "    exp = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "    return exp / np.sum(exp, axis=1, keepdims=True)\n"
      ],
      "metadata": {
        "id": "OvuIg_6E3xeh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, layer_sizes, activation=\"relu\", lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.weights = []\n",
        "        self.biases  = []\n",
        "\n",
        "        for i in range(len(layer_sizes)-1):\n",
        "            self.weights.append(\n",
        "                np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2/layer_sizes[i])\n",
        "            )\n",
        "            self.biases.append(np.zeros((1, layer_sizes[i+1])))\n",
        "\n",
        "        acts = {\n",
        "            \"relu\": (relu, relu_deriv),\n",
        "            \"sigmoid\": (sigmoid, sigmoid_deriv),\n",
        "            \"tanh\": (tanh, tanh_deriv)\n",
        "        }\n",
        "        self.act, self.act_deriv = acts[activation]\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z, self.a = [], [X]\n",
        "\n",
        "        for i in range(len(self.weights)-1):\n",
        "            z = self.a[-1] @ self.weights[i] + self.biases[i]\n",
        "            self.z.append(z)\n",
        "            self.a.append(self.act(z))\n",
        "\n",
        "        z = self.a[-1] @ self.weights[-1] + self.biases[-1]\n",
        "        self.z.append(z)\n",
        "        self.a.append(softmax(z))\n",
        "        return self.a[-1]\n",
        "\n",
        "    def compute_loss(self, y_pred, y_true):\n",
        "        return -np.mean(np.sum(y_true*np.log(y_pred+1e-9), axis=1))\n",
        "\n",
        "    def backward(self, y_true):\n",
        "        m = y_true.shape[0]\n",
        "        dW, dB = [None]*len(self.weights), [None]*len(self.biases)\n",
        "\n",
        "        dz = self.a[-1] - y_true\n",
        "        dW[-1] = self.a[-2].T @ dz / m\n",
        "        dB[-1] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "        for i in reversed(range(len(self.weights)-1)):\n",
        "            dz = (dz @ self.weights[i+1].T) * self.act_deriv(self.z[i])\n",
        "            dW[i] = self.a[i].T @ dz / m\n",
        "            dB[i] = np.sum(dz, axis=0, keepdims=True) / m\n",
        "\n",
        "        self.dW, self.dB = dW, dB\n",
        "\n",
        "    def update_parameters(self):\n",
        "        for i in range(len(self.weights)):\n",
        "            self.weights[i] -= self.lr * self.dW[i]\n",
        "            self.biases[i]  -= self.lr * self.dB[i]\n",
        "\n",
        "    def evaluate(self, loader):\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "        for images, labels in loader:\n",
        "            X, y = preprocess(images, labels)\n",
        "            pred = self.forward(X)\n",
        "            loss = self.compute_loss(pred, y)\n",
        "\n",
        "            total_loss += loss * X.shape[0]\n",
        "            correct += np.sum(np.argmax(pred,1)==np.argmax(y,1))\n",
        "            total += X.shape[0]\n",
        "\n",
        "        return total_loss/total, correct/total\n"
      ],
      "metadata": {
        "id": "QHKuYOzv3yeE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, epochs):\n",
        "    for _ in range(epochs):\n",
        "        for images, labels in train_loader:\n",
        "            X, y = preprocess(images, labels)\n",
        "            model.forward(X)\n",
        "            model.backward(y)\n",
        "            model.update_parameters()\n",
        "\n",
        "    train_loss, train_acc = model.evaluate(train_loader)\n",
        "    val_loss, val_acc = model.evaluate(val_loader)\n",
        "    return train_loss, train_acc, val_loss, val_acc\n"
      ],
      "metadata": {
        "id": "74rpFbOR4pRV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiments = [\n",
        "    {\"lr\": 0.01, \"epochs\": 5, \"activation\": \"relu\",    \"layers\": [784, 128, 10]},\n",
        "    {\"lr\": 0.001,\"epochs\": 5, \"activation\": \"relu\",    \"layers\": [784, 128, 10]},\n",
        "    {\"lr\": 0.01, \"epochs\": 8, \"activation\": \"tanh\",    \"layers\": [784, 128, 10]},\n",
        "    {\"lr\": 0.01, \"epochs\": 8, \"activation\": \"sigmoid\", \"layers\": [784, 128, 10]},\n",
        "    {\"lr\": 0.01, \"epochs\": 8, \"activation\": \"relu\",    \"layers\": [784, 256, 128, 10]},\n",
        "    {\"lr\": 0.005,\"epochs\": 10,\"activation\": \"relu\",    \"layers\": [784, 512, 256, 10]},\n",
        "]\n"
      ],
      "metadata": {
        "id": "-0WfUkuQ4qmn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "\n",
        "for i, exp in enumerate(experiments, 1):\n",
        "    print(f\"\\nRunning Experiment {i}\")\n",
        "    model = NeuralNetwork(exp[\"layers\"], exp[\"activation\"], exp[\"lr\"])\n",
        "    tl, ta, vl, va = train_and_evaluate(model, exp[\"epochs\"])\n",
        "\n",
        "    results.append([i, exp[\"lr\"], exp[\"epochs\"], exp[\"activation\"],\n",
        "                    str(exp[\"layers\"]), round(tl,4), round(ta,4),\n",
        "                    round(vl,4), round(va,4)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl4V5oMI4rsR",
        "outputId": "7d7be62b-a102-457e-8925-d92f07f1511b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running Experiment 1\n",
            "\n",
            "Running Experiment 2\n",
            "\n",
            "Running Experiment 3\n",
            "\n",
            "Running Experiment 4\n",
            "\n",
            "Running Experiment 5\n",
            "\n",
            "Running Experiment 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nRESULT SUMMARY\")\n",
        "print(\"=\"*115)\n",
        "\n",
        "print(f\"{'ID':<4} {'LR':<8} {'EPOCHS':<8} {'ACT':<10} {'LAYERS':<20} \"\n",
        "      f\"{'TR_LOSS':<10} {'TR_ACC':<10} {'VAL_LOSS':<10} {'VAL_ACC':<10}\")\n",
        "\n",
        "print(\"-\"*115)\n",
        "\n",
        "for r in results:\n",
        "    print(f\"{r[0]:<4} {r[1]:<8} {r[2]:<8} {r[3]:<10} {r[4]:<20} \"\n",
        "          f\"{r[5]:<10} {r[6]:<10} {r[7]:<10} {r[8]:<10}\")\n",
        "\n",
        "print(\"=\"*115)\n",
        "print(\"Note: Higher accuracy and lower loss indicate better performance.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEn6W2Yh4s79",
        "outputId": "d7fa4477-427e-487f-b147-89837d212690"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RESULT SUMMARY\n",
            "===================================================================================================================\n",
            "ID   LR       EPOCHS   ACT        LAYERS               TR_LOSS    TR_ACC     VAL_LOSS   VAL_ACC   \n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "1    0.01     5        relu       [784, 128, 10]       0.2835     0.9196     0.2752     0.9203    \n",
            "2    0.001    5        relu       [784, 128, 10]       0.629      0.8532     0.6043     0.8632    \n",
            "3    0.01     8        tanh       [784, 128, 10]       0.2748     0.9222     0.2661     0.9244    \n",
            "4    0.01     8        sigmoid    [784, 128, 10]       0.42       0.8895     0.4009     0.8972    \n",
            "5    0.01     8        relu       [784, 256, 128, 10]  0.1668     0.9529     0.1733     0.9495    \n",
            "6    0.005    10       relu       [784, 512, 256, 10]  0.1999     0.9428     0.2009     0.9423    \n",
            "===================================================================================================================\n",
            "Note: Higher accuracy and lower loss indicate better performance.\n"
          ]
        }
      ]
    }
  ]
}